# Анализ алгоритма сортировки выбором
### Определение
Алгоритм сортировки выбором (Selection Sort) — это алгоритм, который на каждом шаге находит минимальный элемент среди последних и меняют его местами с текущим элементом в массиве.
### Объяснение работы алгоритма: 
•	На каждом шаге ищется самый маленький элемент в оставшейся неотсортированной части массива (for (int j = i + 1; j < n; j++)).

•	Этот минимальный элемент меняется местами с первым элементом этой части массива (arr[i] = arr[min_idx]).

•	После этого считается, что эта часть массива отсортирована, и алгоритм переходит к следующему элементу и оставшейся части массива (for (int i = 0; i < n; i++)).

•	Процесс повторяется, пока весь массив не станет отсортирован.
### Временная сложность
Временная сложность — O(n²). 
### Почему: наличие внешнего и внутреннего циклов приводит к временной сложности O(n²).
### Результат программы на С++:
До сортировки: 64 25 12 22 11 

После сортировки: 11 12 22 25 64 
#
# Анализ алгоритма сортировки обменом (пузырьком)
### Определение
Алгоритм сортировка обменом (пузырьком) (Bubble Sort) — это алгоритм, который проходит по списку несколько раз, сравнивая соседние элементы и меняя их местами, если они находятся в неправильном порядке. Процесс повторяется до тех пор, пока список полностью не отсортируется.
### Объяснение работы алгоритма:
•	Алгоритм проходит по массиву, сравнивая каждый элемент со следующим (for (int j = 0; j < n - i - 1; j++)).

•	Если текущий элемент больше следующего, они меняются местами (if (arr[j] > arr[j + 1])).

•	После каждого полного прохода наибольший из неотсортированных элементов "всплывает" в конец массива, занимая свою окончательную позицию.

•	Процесс повторяется для всех элементов, пока массив не будет полностью отсортирован (for (int i = 0; i < n - 1; i++)).
### Временная сложность
Временная сложность — O(n²).
### Почему: Наличие вложенных циклов приводит к тому, что количество операций пропорционально квадрату размера массива. Первый проход выполняет n-1 сравнений, второй n-2, и так далее, что в сумме дает O(n²).
### Результат программы на С++:
До сортировки: 5 1 4 2 8 

После сортировки: 1 2 4 5 8 
#
# Анализ алгоритма сортировки вставками 
### Определение
Алгоритм сортировки вставками (Insertion Sort) — это алгоритм, который строит отсортированную часть массива, постепенно вставляя каждый новый элемент в правильную позицию среди уже упорядоченных элементов.
### Объяснение работы алгоритма:
•	Алгоритм начинает со второго элемента массива и последовательно обрабатывает все элементы справа от него (for (int i = 1; i < size; i++)).

•	Для каждого текущего элемента (key) происходит поиск правильной позиции в уже отсортированной левой части массива.

•	Элементы, большие чем key, сдвигаются на одну позицию вправо, чтобы освободить место для вставки (while (j >= 0 && arr[j] > key)).

•	Текущий элемент вставляется на найденную правильную позицию в отсортированной части массива (arr[j + 1] = key).
### Временная сложность
Временная сложность — O(n²).
### Почему: Наличие вложенного цикла while внутри внешнего цикла for приводит к квадратичной сложности.
### Результат программы на С++:
До сортировки: 9 5 1 4 3 

После сортировки: 1 3 4 5 9 
#
# Анализ алгоритма сортировки слиянием
### Определение 
Алгоритм сортировки слиянием (Merge Sort) — это алгоритм, который использует стратегию «разделяй и властвуй», рекурсивно разделяя массив на две половины, сортируя их и затем объединяя отсортированные половины в один упорядоченный массив.
### Объяснение работы алгоритма:
•	Массив рекурсивно разделяется на две примерно равные части до тех пор, пока не останутся подмассивы размером в один элемент (mergeSort(arr, l, m) и mergeSort(arr, m+1, r)).

•	Каждая пара отсортированных подмассивов объединяется в один отсортированный массив с помощью процедуры слияния.

•	При слиянии сравниваются элементы из двух подмассивов и выбирается наименьший для помещения в результирующий массив (while(i < tempLeft.size() && j < tempRight.size())).

•	Оставшиеся элементы из любого подмассива добавляются в конец результирующего массива.
### Временная сложность
Временная сложность — O(n log n).
### Почему: Алгоритм рекурсивно делит массив пополам, создавая log n уровней рекурсии. На каждом уровне выполняется операция слияния с линейной сложностью O(n). Перемножение этих величин дает общую сложность O(n log n).
### Результат программы на С++:
Отсортированный массив: 3 9 10 27 38 43 82 
#
# Анализ алгоритма сортировки Шелла
### Определение 
Алгоритм сортировки Шелла (Shell Sort) — это алгоритм, который является обобщением сортировки вставками и сортирует элементы, находящиеся на определенном расстоянии друг от друга, постепенно уменьшая это расстояние до единицы.
### Объяснение работы алгоритма:
•	Алгоритм начинается с большого шага (расстояния между сравниваемыми элементами), который постепенно уменьшается (h //= 3).

•	На каждом шаге выполняется сортировка вставками для элементов, расположенных на расстоянии h друг от друга (for i in range(h, n)).

•	Элементы сравниваются и перемещаются внутри своих подпоследовательностей, пока не будут упорядочены относительно шага h (while j >= h and arr[j-h] > temp).

•	Процесс повторяется с уменьшающимся шагом до тех пор, пока шаг не станет равным 1, после чего выполняется финальная сортировка вставками.
### Временная сложность
Временная сложность — от O(n log²n) до O(n²) в зависимости от выбранной последовательности шагов.
### Почему: Алгоритм использует вложенные циклы, но внутренний цикл (по j) не всегда проходит n раз, как в пузырьке. Количество итераций зависит от gap. В среднем случае количество итераций внутреннего цикла растет медленнее, чем n, приводя к сложности между O(n) и O(n^2).
### Результат программы на Python:
Исходный массив: [8, 5, 3, 9, 1, 6, 4, 2, 7]

Отсортированный массив: [1, 2, 3, 4, 5, 6, 7, 8, 9]
#
# Анализ алгоритма быстрой сортировки
### Определение 
Алгоритм быстрой сортировки (Quick Sort) — это алгоритм, который использует стратегию «разделяй и властвуй», выбирая опорный элемент и разделяя массив на две части: элементы меньше опорного и элементы больше опорного, после чего рекурсивно сортирует эти части.
### Объяснение работы алгоритма:
•	Если массив содержит 0 или 1 элемент, он считается уже отсортированным (if len(arr) <= 1).

•	Выбирается опорный элемент — в данной реализации средний элемент массива (pivot = arr[len(arr)//2]).

•	Массив разделяется на три части: элементы меньше опорного, равные опорному и больше опорного (left = [x for x in arr if x < pivot], middle = [x for x in arr if x == pivot], right = [x for x in arr if x > pivot]).

•	Алгоритм рекурсивно применяется к левой и правой частям, после чего результаты объединяются (return quicksort(left) + middle + quicksort(right)).
### Временная сложность
Временная сложность — O(n log n) в среднем случае, O(n²) в худшем случае.
### Почему: В среднем случае массив делится пополам на каждом уровне рекурсии, создавая log n уровней, на каждом из которых выполняется O(n) операций. В худшем случае (когда опорный элемент всегда минимальный или максимальный) глубина рекурсии составляет n уровней, что дает O(n²).
### Результат программы на Python:
Отсортированный массив: [1, 1, 2, 3, 6, 8, 10]
#
# Анализ пирамидальной сортировки
### Определение
Алгоритм пирамидальной сортировки (Heap Sort) — это алгоритм, который использует структуру данных «двоичная куча» для сортировки элементов путем построения max-кучи и последовательного извлечения максимального элемента в конец массива.
### Объяснение работы алгоритма:
•	Сначала массив преобразуется в max-кучу, где каждый родительский элемент больше своих дочерних (for (int i = n / 2 - 1; i >= 0; i--) heapify(arr, n, i)).

•	На каждом шаге максимальный элемент (корень кучи) перемещается в конец массива (swap(arr[0], arr[i])).

•	После перемещения максимального элемента структура кучи восстанавливается для оставшихся элементов (heapify(arr, i, 0)).

•	Процесс повторяется до тех пор, пока в куче не останется один элемент.
### Временная сложность
Временная сложность — O(n log n).
### Почему: Построение кучи имеет сложность O(n), а каждая из n операций извлечения максимального элемента требует O(log n) времени для восстановления свойств кучи. Итоговая сложность составляет O(n) + O(n log n) = O(n log n).
### Результат программы на С++:
Исходный массив: 12 11 13 5 6 7 

Отсортированный массив: 5 6 7 11 12 13 
#
# Анализ последовательного поиска
### Определение
Алгоритм последовательного (линейного) поиска (Sequential Search) — это алгоритм, который осуществляет поиск заданного элемента в массиве путем последовательного сравнения каждого элемента с искомым значением до тех пор, пока не будет найдено совпадение или не будут проверены все элементы.
### Объяснение работы алгоритма:
•	Алгоритм последовательно перебирает все элементы массива, начиная с первого (for index, value in enumerate(arr)).

•	На каждом шаге текущий элемент сравнивается с искомым значением (if value == target).

•	Если находится совпадение, алгоритм немедленно возвращает индекс найденного элемента (return index).

•	Если после проверки всех элементов совпадение не найдено, алгоритм возвращает None (return None).
### Временная сложность
Временная сложность — O(n) в худшем и среднем случае, O(1) в лучшем случае.
### Почему: В худшем случае (элемент отсутствует или находится в конце) алгоритм проверяет все n элементов. В среднем случае проверяется около n/2 элементов. В лучшем случае (элемент первый) требуется только одна проверка.
### Результат программы на Python:
Значение 30 найдено на индексе 2
#
# Анализ бинарного поиска
### Определение
Алгоритм бинарного поиска (Binary Search) — это алгоритм, который осуществляет поиск заданного элемента в отсортированном массиве путем многократного деления интервала поиска пополам и сравнения среднего элемента с искомым значением.
### Объяснение работы алгоритма:
•	Алгоритм начинает с установки границ поиска на весь массив (low = 0, high = len(arr) - 1).

•	На каждой итерации вычисляется средний элемент текущего интервала (mid = (low + high) // 2).

•	Если средний элемент равен искомому, возвращается его индекс (if arr[mid] == target: return mid).

•	Если средний элемент меньше искомого, поиск продолжается в правой половине (low = mid + 1).

•	Если средний элемент больше искомого, поиск продолжается в левой половине (high = mid - 1).

•	Процесс повторяется до тех пор, пока элемент не будет найден или интервал поиска не станет пустым.
### Временная сложность
Временная сложность — O(log n).
### Почему: На каждой итерации алгоритм уменьшает область поиска вдвое. В худшем случае количество операций пропорционально логарифму от количества элементов в массиве.
### Результат программы на Python:
Элемент 7 найден на позиции 3.
#
# Анализ интерполирующего поиска
### Определение
Алгоритм интерполирующего поиска (Interpolation Search) — это алгоритм поиска в отсортированном массиве, который предсказывает позицию искомого элемента на основе его значения и распределения данных в массиве, что делает его более эффективным чем бинарный поиск при равномерном распределении элементов.
### Объяснение работы алгоритма:
•	Алгоритм вычисляет предполагаемую позицию элемента с помощью интерполяционной формулы (int pos = low + (((double)(high - low) / (arr[high] - arr[low])) * (key - arr[low]))).
•	Если элемент в вычисленной позиции равен искомому, возвращается его индекс (if (arr[pos] == key) return pos).

•	Если искомый элемент больше элемента в вычисленной позиции, поиск продолжается в правой части массива (low = pos + 1).


•	Если искомый элемент меньше элемента в вычисленной позиции, поиск продолжается в левой части массива (high = pos - 1).

•	Поиск завершается когда элемент найден или когда границы поиска пересекаются.
### Временная сложность
Временная сложность — O(log log n) в среднем случае при равномерном распределении, O(n) в худшем случае.
### Почему: При равномерном распределении данных алгоритм быстро сужает область поиска, достигая логарифмической от логарифма сложности. В худшем случае (неравномерное распределение) алгоритм может деградировать до линейного поиска.
### Результат программы на С++:
Элемент найден на позиции: 4
#
# Анализ поиска по Фибоначчи
### Определение
Алгоритм поиска Фибоначчи (Fibonacci Search) — это алгоритм поиска в отсортированном массиве, который использует числа Фибоначчи для определения позиций сравнения, что позволяет эффективно сужать область поиска без использования операции деления.
### Объяснение работы алгоритма:
•	Алгоритм начинает с генерации последовательности чисел Фибоначчи, достаточной для покрытия размера массива (while b < len(arr): fib_numbers.append(b)).

•	На каждой итерации вычисляется позиция для сравнения с использованием чисел Фибоначчи (idx = min(offset+fib_numbers[m-1], len(arr)-1).

•	Если текущий элемент меньше искомого, поиск продолжается в правой части массива (offset = idx, m -= 1).

•	Если текущий элемент больше искомого, поиск продолжается в левой части массива (m -= 2).

•	Если элемент найден, возвращается его индекс (return idx).

•	Процесс повторяется до тех пор, пока не будет найден элемент или не исчерпаются числа Фибоначчи.
### Временная сложность
Временная сложность — O(log n).
### Почему: Алгоритм делит массив на части, пропорциональные числам Фибоначчи, что обеспечивает логарифмическую сложность, аналогичную бинарному поиску, но без использования операции деления.
### Результат программы на Python:
Элемент 85 найден на позиции 8
#
